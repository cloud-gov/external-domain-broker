#!/usr/bin/env bash

set -euo pipefail
shopt -s inherit_errexit 2>/dev/null || true

built_image_name="external-domain-broker-dev"

main() {
  [[ $# -eq 0 ]] && usage "Expected command."
  [[ -v DEBUG ]] && set -x

  cd "$(git rev-parse --show-toplevel)"

  command="$1"
  shift

  case $command in
    -h)
      usage
      ;;
    serve)
      build_image
      serve "$@"
      ;;
    tests)
      build_image
      tests "$@"
      ;;
    watch-tests)
      build_image
      watch-tests "$@"
      ;;
    run)
      build_image
      run "$@"
      ;;
    new-migration)
      build_image
      new-migration "$@"
      ;;
    upgrade-requirements)
      build_image
      upgrade-requirements "$@"
      ;;
    update-requirements)
      build_image
      update-requirements "$@"
      ;;
    shell)
      build_image
      shell
      ;;
    *)
      usage "Unknown command: $command"
      ;;
  esac
}

build_image() {
  # The build-args are used to create a user with the same UID/GID as
  # yourself. That way, any files written to the $PWD mount will be owned by
  # you.  This user is embedded in the docker image, so the resulting image
  # should only be used locally.  These arguments are not used in our
  # concourse pipeline.
  echo "Building image..."
  docker build \
    --file=docker/Dockerfile.dev \
    --tag=${built_image_name} \
    --build-arg UID="$(id -u)" \
    --build-arg GID="$(id -g)" \
    --build-arg USER="$USER" \
    .
}

run_docker() {
  docker run \
    --rm \
    -it \
    -v "$PWD:/app" \
    "${built_image_name}" \
    "$*"
}

run_docker_read_only() {
  docker \
    run \
    --rm \
    -it \
    -v "$PWD:/app:ro" \
    -v "$PWD/tmp:/app/tmp:rw" \
    -v "$PWD/logs:/app/logs:rw" \
    -v "$PWD/.pytest_cache:/app/.pytest_cache:rw" \
    "${built_image_name}" \
    "$*"
}

run_docker_exposed() {
  docker run \
    --rm \
    -it \
    -v "$PWD:/app" \
    -p "0.0.0.0:8000:8000" \
    "${built_image_name}" \
    "$*"
}

tests() {
  run_docker_read_only docker/tests "$@"
}

watch-tests() {
  run_docker_read_only docker/tests watch "$@"
}

run() {
  run_docker "$@"
}

shell() {
  run "./docker/start-servers.sh && bash"
}

serve() {
  run_docker_exposed docker/serve "$@"
}

update-requirements() {
  run "docker/update-requirements-txt"
}

upgrade-requirements() {
  run "docker/upgrade-requirements-txt"
}

new-migration() {
  [[ "$#" -eq 1 ]] || usage "Missing migration description"
  run "./docker/start-servers.sh && flask db upgrade && flask db migrate -m \"$1\""
}

usage() {
  [[ $# -gt 0 ]] && echo "ERROR: $*"
  local me=$(basename "$0")
  cat <<-EOF

  USAGE: $me COMMAND

  Run workflows via the development docker image.

  This provides a consistent developer experience, and avoids the "works on my
  laptop" issue.

  Examples:

    # Run the tests once
    $me

    # Same as above
    $me tests

    # Run the application, binding to port 8000
    $me serve

    # Continually watch for file changes and runs tests
    $me watch-tests

    # Start an interactive bash shell in the tests container
    $me shell

    # Create a new database migration file.
    # The new file will be in migrations/versions/
    $me new-migration "Add sprocket column to widget table"

    # Generate the pip-tools/*requirements.txt files from
    # pip-tools/*requirements.in
    $me update-requirements

    # Run command 'foo' in the container
    $me run foo
	EOF
  exit 1
}

main "$@"
